{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WPILib ML Notebook\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "By using this notebook, you can train a TensorFlow Lite model for use on a Raspberry Pi and Google Coral USB Accelerator. We've designed this process to be as simple as possible. If you find an issue with this notebook, please create a new issue report on our GitHub page, where you downloaded this notebook.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "This section will explain the four distinct steps to getting a trained model to run on your hardware.\n",
    "### Getting Data\n",
    "\n",
    "WPILib provides thousands of labelled images for this years game, which you can download here. However, you can train with custom data using this notebook as well. The below instructions describe how to gather and label your own data.\n",
    "\n",
    "1. Plug a USB Camera into your laptop, and run a script similar to record_video.py, which simply makes an mp4 from the camera stream.\n",
    "2. Create a [supervise.ly](supervise.ly) account. This is a very nice tool for labelling data.\n",
    "3. (Optional) You can add other teammates to your Supervise.ly workspace by clicking 'Members' on the left and then 'INVITE' at the top.\n",
    "4. Choose a workspace to work in, in the 'Workspaces' tab.\n",
    "5. Upload the official WPILib labelled data to your workspace. Download the tar here, extract it, then click 'IMPORT DATA' or 'UPLOAD' inside of your workspace. Change the import plugin to Supervisely, then drag in the extracted FOLDER. Then, give the project a name, then click import.\n",
    "6. Upload your own video to your workspace. Click 'UPLOAD' when inside of your workspace, change your import plugin to video, drag in your video, give the project a name, and click import.\n",
    "7. Click into your newly import Dataset. Use the rectangle tool to draw appropriate boxes around the objects which you wish to label.\n",
    "\n",
    "### Training\n",
    "\n",
    "1. Download your datasets from Supervise.ly. Select the \"json and jpeg\" option.\n",
    "2. Upload your tar to a new folder in an Amazon S3 bucket, or a brand new S3 bucket.\n",
    "3. Create a new SageMaker notebook instance, and open the WPILib notebook.\n",
    "4. Change estimator.fit() to use your new dataset, by specifying the folder in which the tar is stored.\n",
    "5. Run each block of the notebook in order.\n",
    "6. Training should take roughly 45 minutes. If you do not change anything in the notebook, it should absolutely not take longer than an hour. In the Training Job, CPU usage should be around 690 during the majority of the training, if running on an ml.c4.2xlarge. If it is less, something went wrong.\n",
    "\n",
    "### Inference\n",
    "\n",
    "1. Go to the training job in SageMaker, scroll to the bottom, and find the output S3 location\n",
    "2. Download the the tar file in the bucket, extract it, and get your .tflite file\n",
    "3. Put the tflite on your Raspberry Pi by plugging in the SD card into your computer and dragging it in to /home/pi\n",
    "4. Run the python script, using `python3 object_detection.py --model output.tflite`\n",
    "\n",
    "\n",
    "## Notebook\n",
    "### Building and registering the container\n",
    "\n",
    "This code block runs a script that builds a docker container, and saves it as an Amazon ECR image. This image is used by the training instance so that all proper dependencies and WPILib files are in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reclaimed space: 0B\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  65.02kB\n",
      "Step 1/16 : FROM tensorflow/tensorflow:1.12.0-rc2-devel\n",
      " ---> f643a5376d9c\n",
      "Step 2/16 : RUN git clone https://github.com/tensorflow/models.git &&     mv models /tensorflow/models\n",
      " ---> Running in 88d1d1d730d2\n",
      "\u001b[91mCloning into 'models'...\n",
      "\u001b[0mRemoving intermediate container 88d1d1d730d2\n",
      " ---> 1f883f22e959\n",
      "Step 3/16 : RUN apt-get update -qq > /dev/null &&     apt-get install -y python python-tk python3 python3-pip -qq > /dev/null\n",
      " ---> Running in 271b7d2d2e59\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mRemoving intermediate container 271b7d2d2e59\n",
      " ---> 608d1a9c8c80\n",
      "Step 4/16 : RUN apt-get update -qq > /dev/null &&     apt-get install -y --no-install-recommends nginx curl -qq > /dev/null\n",
      " ---> Running in 752dd175ded9\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mRemoving intermediate container 752dd175ded9\n",
      " ---> dae35625face\n",
      "Step 5/16 : RUN pip install Cython contextlib2  pillow lxml jupyter matplotlib pandas -q &&     python3 -m pip install pandas\n",
      " ---> Running in afbdd54f7969\n",
      "\u001b[91mYou are using pip version 18.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mCollecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/d9/e03b615e973c2733ff8fd53d95bd3633ecbfa81b5af2f83fe39647c02344/pandas-0.25.0-cp35-cp35m-manylinux1_x86_64.whl (10.3MB)\n",
      "Collecting python-dateutil>=2.6.1 (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
      "Collecting numpy>=1.13.3 (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/69/25/eef8d362bd216b11e7d005331a3cca3d19b0aa57569bde680070109b745c/numpy-1.17.0-cp35-cp35m-manylinux1_x86_64.whl (20.2MB)\n",
      "Collecting pytz>=2017.2 (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.6.1->pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Installing collected packages: six, python-dateutil, numpy, pytz, pandas\n",
      "Successfully installed numpy-1.17.0 pandas-0.25.0 python-dateutil-2.8.0 pytz-2019.1 six-1.12.0\n",
      "\u001b[91mYou are using pip version 8.1.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container afbdd54f7969\n",
      " ---> 29060ff9cfd5\n",
      "Step 6/16 : RUN curl -s -OL \"https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\" > /dev/null &&     unzip protoc-3.0.0-linux-x86_64.zip -d proto3 > /dev/null &&     mv proto3/bin/* /usr/local/bin &&     mv proto3/include/* /usr/local/include &&     rm -rf proto3 protoc-3.0.0-linux-x86_64.zip\n",
      " ---> Running in 4cd19d23ee63\n",
      "Removing intermediate container 4cd19d23ee63\n",
      " ---> 881950a00b8a\n",
      "Step 7/16 : RUN git clone --depth 1 https://github.com/cocodataset/cocoapi.git &&     cd cocoapi/PythonAPI &&     make -j8 &&     cp -r pycocotools /tensorflow/models/research &&     cd ../../ &&     rm -rf cocoapi\n",
      " ---> Running in 1e9495c9909a\n",
      "\u001b[91mCloning into 'cocoapi'...\n",
      "\u001b[0mpython setup.py build_ext --inplace\n",
      "running build_ext\n",
      "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
      "\u001b[91m/usr/local/lib/python2.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /root/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "\u001b[0mbuilding 'pycocotools._mask' extension\n",
      "creating build\n",
      "creating build/common\n",
      "creating build/temp.linux-x86_64-2.7\n",
      "creating build/temp.linux-x86_64-2.7/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I../common -I/usr/include/python2.7 -c ../common/maskApi.c -o build/temp.linux-x86_64-2.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "\u001b[91m../common/maskApi.c: In function 'rleToBbox':\n",
      "\u001b[0m\u001b[91m../common/maskApi.c:141:31: warning: 'xp' may be used uninitialized in this function [-Wmaybe-uninitialized]\n",
      "       if(j%2==0) xp=x; else if(xp<x) { ys=0; ye=h-1; }\n",
      "                               ^\n",
      "\u001b[0mx86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I../common -I/usr/include/python2.7 -c pycocotools/_mask.c -o build/temp.linux-x86_64-2.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "creating build/lib.linux-x86_64-2.7\n",
      "creating build/lib.linux-x86_64-2.7/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wl,-Bsymbolic-functions -Wl,-z,relro -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security build/temp.linux-x86_64-2.7/../common/maskApi.o build/temp.linux-x86_64-2.7/pycocotools/_mask.o -o build/lib.linux-x86_64-2.7/pycocotools/_mask.so\n",
      "copying build/lib.linux-x86_64-2.7/pycocotools/_mask.so -> pycocotools\n",
      "rm -rf build\n",
      "Removing intermediate container 1e9495c9909a\n",
      " ---> 758d0b9ab358\n",
      "Step 8/16 : RUN cd /tensorflow/models/research &&     protoc object_detection/protos/*.proto --python_out=.\n",
      " ---> Running in bbe3a18ead2d\n",
      "Removing intermediate container bbe3a18ead2d\n",
      " ---> bdbb078adf6d\n",
      "Step 9/16 : ENV PYTHONPATH $PYTHONPATH:/tensorflow/models/research:/tensorflow/models/research/slim\n",
      " ---> Running in 32b53f87ab6f\n",
      "Removing intermediate container 32b53f87ab6f\n",
      " ---> c808eaa128f3\n",
      "Step 10/16 : RUN apt-get update -qq > /dev/null &&     apt-get install -y wget vim emacs nano -qq > /dev/null\n",
      " ---> Running in ecbd659e2dad\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mRemoving intermediate container ecbd659e2dad\n",
      " ---> c08b42f14dce\n",
      "Step 11/16 : ARG work_dir=/tensorflow/models/research\n",
      " ---> Running in a0e8dc39c239\n",
      "Removing intermediate container a0e8dc39c239\n",
      " ---> 3977769ab47c\n",
      "Step 12/16 : ARG scripts_link=\"http://storage.googleapis.com/cloud-iot-edge-pretrained-models/docker/obj_det_scripts.tgz\"\n",
      " ---> Running in eba0542e3e9f\n",
      "Removing intermediate container eba0542e3e9f\n",
      " ---> a75783501c1b\n",
      "Step 13/16 : RUN cd ${work_dir} &&     wget -q -O obj_det_scripts.tgz ${scripts_link} &&     tar zxf obj_det_scripts.tgz\n",
      " ---> Running in 10d54272f116\n",
      "Removing intermediate container 10d54272f116\n",
      " ---> f2b90e602ba6\n",
      "Step 14/16 : COPY /coral /tensorflow/models/research\n",
      " ---> ebfd39bf3961\n",
      "Step 15/16 : ENV PATH $PATH:/tensorflow/models/research\n",
      " ---> Running in 212285e4c485\n",
      "Removing intermediate container 212285e4c485\n",
      " ---> d3ffbe5218f8\n",
      "Step 16/16 : WORKDIR ${work_dir}\n",
      " ---> Running in c74f34f55b60\n",
      "Removing intermediate container c74f34f55b60\n",
      " ---> 97532224b944\n",
      "Successfully built 97532224b944\n",
      "Successfully tagged sagemaker-tf-wpi2:latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "#!/usr/bin/env bash\n",
    "docker system prune --force > /dev/null 2>&1\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-tf-wpi2\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod -R +x coral/\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} . --no-cache > /dev/null 2>&1\n",
    "docker tag ${algorithm_name} ${fullname} > /dev/null 2>&1\n",
    "\n",
    "docker push ${fullname} > /dev/null 2>&1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get execution role\n",
    "\n",
    "This gets the notebook instance's execution role, used for communicating with the training instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on SageMaker\n",
    "Training a model on SageMaker with the Python SDK is done in a way that is similar to the way we trained it locally. This is done by changing our train_instance_type from `local` to one of our [supported EC2 instance types](https://aws.amazon.com/sagemaker/pricing/instance-types/).\n",
    "\n",
    "In addition, we must now specify the ECR image URL, which we just pushed above.\n",
    "\n",
    "Finally, our local training dataset has to be in Amazon S3 and the S3 URL to our dataset is passed into the `fit()` call.\n",
    "\n",
    "Let's first fetch our ECR image url that corresponds to the image we just built and pushed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766711008027.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tf-wpi2:latest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "\n",
    "algorithm_name = 'sagemaker-tf-wpi2'\n",
    "\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This last step runs the training instance (default an ml.c4.2xlarge), and begins training with the data specified in `fit()`\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-29 19:43:34 Starting - Starting the training job...\n",
      "2019-07-29 19:43:37 Starting - Launching requested ML instances......\n",
      "2019-07-29 19:44:38 Starting - Preparing the instances for training...\n",
      "2019-07-29 19:45:18 Downloading - Downloading input data...\n",
      "2019-07-29 19:45:52 Training - Downloading the training image........\n",
      "\u001b[31mDownloading model\u001b[0m\n",
      "\u001b[31mPreparing checkpoint\u001b[0m\n",
      "\n",
      "2019-07-29 19:47:18 Training - Training image download completed. Training in progress.\u001b[31mSuccessfully created the TFRecords: /opt/ml/input/data/training/train.record\u001b[0m\n",
      "\u001b[31mSuccessfully created the TFRecords: /opt/ml/input/data/training/eval.record\u001b[0m\n",
      "\u001b[31mData made.\u001b[0m\n",
      "\u001b[31mitem {\n",
      "\u001b[0m\n",
      "\u001b[31mid: 1\n",
      "\u001b[0m\n",
      "\u001b[31mname: \"stickyvelcro\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mitem {\n",
      "\u001b[0m\n",
      "\u001b[31mid: 2\n",
      "\u001b[0m\n",
      "\u001b[31mname: \"redrobot\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mitem {\n",
      "\u001b[0m\n",
      "\u001b[31mid: 3\n",
      "\u001b[0m\n",
      "\u001b[31mname: \"hole\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mitem {\n",
      "\u001b[0m\n",
      "\u001b[31mid: 4\n",
      "\u001b[0m\n",
      "\u001b[31mname: \"bluerobot\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mitem {\n",
      "\u001b[0m\n",
      "\u001b[31mid: 5\n",
      "\u001b[0m\n",
      "\u001b[31mname: \"alignmentmarks\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mitem {\n",
      "\u001b[0m\n",
      "\u001b[31mid: 6\n",
      "\u001b[0m\n",
      "\u001b[31mname: \"Cargo\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mitem {\n",
      "\u001b[0m\n",
      "\u001b[31mid: 7\n",
      "\u001b[0m\n",
      "\u001b[31mname: \"Hatchcover\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31m./opt/ml/input/data/training/train.record\u001b[0m\n",
      "\u001b[31mBeginning training on Docker image\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# The type of computer used for training. The default is recommended. It costs 45 cents/hour to run.\n",
    "instance_type = 'ml.c4.2xlarge'\n",
    "\n",
    "# The number of epochs to train to. 500 is a safe number. With the default instance, it should take 45 minutes.\n",
    "hyperparameters = {'train-steps': 500}\n",
    "\n",
    "# The estimator object, using our notebook, training instance, the ECR image, and the specified training steps\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name=ecr_image,\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "# Change this bucket if you want to train with your own data. The WPILib bucket contains thousands of high quality labeled images.\n",
    "# s3://wpilib\n",
    "estimator.fit(\"s3://wpilib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### The output\n",
    "\n",
    "Go to the Training Jobs tab of SageMaker. Click on the newest Completed job. Scroll to the bottom. The S3 bucket containing the trained .tflite file (inside of a tar file) can be found there.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}